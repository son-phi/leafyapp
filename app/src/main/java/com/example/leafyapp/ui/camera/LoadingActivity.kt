package com.example.leafyapp.ui.camera

import android.content.Intent
import android.graphics.Bitmap
import android.graphics.BitmapFactory
import android.graphics.Color
import android.net.Uri
import android.os.Bundle
import android.util.Log
import android.view.View
import android.widget.ImageView
import android.widget.TextView
import androidx.appcompat.app.AppCompatActivity
import androidx.lifecycle.lifecycleScope
import com.bumptech.glide.Glide
import com.example.leafyapp.R
import com.example.leafyapp.ui.information.ResultActivity
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import org.tensorflow.lite.Interpreter
import java.io.File
import java.io.InputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder

class LoadingActivity : AppCompatActivity() {

    private lateinit var imageView: ImageView
    private lateinit var tvAnalyzing: TextView
    private lateinit var tvDetecting: TextView
    private lateinit var tvIdentifying: TextView

    // TFLite model names
    private val plantModel = "plant.tflite"
    private val diseaseModel = "disease.tflite"
    private val plantLabels = "plant_labels.txt"
    private val diseaseLabels = "disease_labels.txt"

    // Danh s√°ch c√°c b∆∞·ªõc loading th·ª±c t·∫ø (d√πng cho updateStepText)
    private val loadingSteps = listOf("Analyzing image", "Detecting relevant area", "Identifying result")

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_loading)

        // Setup UI
        window.decorView.systemUiVisibility = View.SYSTEM_UI_FLAG_FULLSCREEN
        window.statusBarColor = Color.BLACK

        // √Ånh x·∫° View
        imageView = findViewById(R.id.imageViewScan)
        tvAnalyzing = findViewById(R.id.tvAnalyzing)
        tvDetecting = findViewById(R.id.tvDetecting)
        tvIdentifying = findViewById(R.id.tvIdentifying)

        // L·∫•y d·ªØ li·ªáu t·ª´ Intent
        val photoPath = intent.getStringExtra("PHOTO_PATH") // C√≥ th·ªÉ l√† File Path HO·∫∂C Uri String
        val scanMode = intent.getStringExtra("SCAN_MODE")

        if (photoPath == null || scanMode == null) {
            Log.e("LoadingActivity", "Photo path or Scan mode is null!")
            finish()
            return
        }

        // T·∫£i ·∫£nh v√†o ImageView: H·ªó tr·ª£ c·∫£ Uri (Gallery) v√† File Path (Camera)
        if (photoPath.startsWith("content://")) {
            Glide.with(this).load(Uri.parse(photoPath)).centerCrop().into(imageView)
        } else {
            Glide.with(this).load(File(photoPath)).centerCrop().into(imageView)
        }

        // üöÄ B·∫Øt ƒë·∫ßu qu√° tr√¨nh nh·∫≠n di·ªán th·ª±c t·∫ø
        startRecognition(photoPath, scanMode)
    }

    private fun startRecognition(imagePath: String, mode: String) {
        // Kh·ªüi t·∫°o tr·∫°ng th√°i ban ƒë·∫ßu
        updateStep(0, false)
        updateStep(1, false)
        updateStep(2, false)

        // ‚úÖ D√πng Coroutine ƒë·ªÉ ch·∫°y model tr√™n lu·ªìng n·ªÅn
        lifecycleScope.launch {
            var recognitionResult: String? = null
            var bitmap: Bitmap? = null

            try {
                // B∆∞·ªõc 1: Analyzing image
                updateStep(0, true)

                // B∆∞·ªõc 2: Detecting relevant area (ƒêang x·ª≠ l√Ω)
                updateStep(1, false)

                // Ch·∫°y model trong lu·ªìng I/O
                recognitionResult = withContext(Dispatchers.IO) {
                    // ƒê·ªçc ·∫£nh th√†nh Bitmap (H·ªó tr·ª£ c·∫£ File Path v√† Uri)
                    bitmap = readBitmapFromPath(imagePath)

                    if (bitmap == null) {
                        Log.e("LoadingActivity", "Failed to decode bitmap from path: $imagePath")
                        return@withContext "Error: Failed to load image."
                    }

                    // Ch·∫°y nh·∫≠n di·ªán TFLite
                    runRecognition(bitmap!!, mode)
                }

                // B∆∞·ªõc 2 & 3: Ho√†n th√†nh Detecting v√† Identifying
                updateStep(1, true)
                updateStep(2, true)

            } catch (e: Exception) {
                Log.e("LoadingActivity", "AI processing failed unexpectedly", e)
                recognitionResult = "Error: ${e.message}"
                updateStep(2, true)
            }

            // 4. ƒêi·ªÅu h∆∞·ªõng ƒë·∫øn m√†n h√¨nh k·∫øt qu·∫£ sau khi x·ª≠ l√Ω xong
            navigateToResultScreen(recognitionResult ?: "Error: Unknown failure.", mode)
        }
    }

    private fun readBitmapFromPath(imagePath: String): Bitmap? {
        return try {
            if (imagePath.startsWith("content://")) {
                // H·ªó tr·ª£ Gallery URI
                contentResolver.openInputStream(Uri.parse(imagePath))?.use {
                    BitmapFactory.decodeStream(it)
                }
            } else {
                // H·ªó tr·ª£ File Path (CameraX)
                BitmapFactory.decodeFile(imagePath)
            }
        } catch (e: Exception) {
            Log.e("LoadingActivity", "Error reading bitmap from path/uri: $imagePath", e)
            null
        }
    }

    private fun runRecognition(bitmap: Bitmap, mode: String): String {
        val modelName = if (mode == "Plant") plantModel else diseaseModel
        val labelsFile = if (mode == "Plant") plantLabels else diseaseLabels

        val labels = assets.open(labelsFile).bufferedReader().readLines()

        // 1. T·∫£i Model
        val modelBytes = assets.open(modelName).readBytes()
        val modelBuffer = ByteBuffer.allocateDirect(modelBytes.size).order(ByteOrder.nativeOrder())
        modelBuffer.put(modelBytes).rewind()

        // S·ª≠ d·ª•ng kh·ªëi try-use ƒë·ªÉ ƒë·∫£m b·∫£o Interpreter ƒë∆∞·ª£c ƒë√≥ng
        Interpreter(modelBuffer).use { interpreter ->

            // 2. Ti·ªÅn x·ª≠ l√Ω ·∫£nh
            val resized = Bitmap.createScaledBitmap(bitmap, 224, 224, true)

            // K√≠ch th∆∞·ªõc Input: [1, 224, 224, 3] v·ªõi Float (4 bytes/float)
            val input = ByteBuffer.allocateDirect(1 * 224 * 224 * 3 * 4).order(ByteOrder.nativeOrder())

            // Chu·∫©n h√≥a [-1, 1]
            for (y in 0 until 224)
                for (x in 0 until 224) {
                    val px = resized.getPixel(x, y)
                    input.putFloat((Color.red(px) - 127.5f) / 127.5f)
                    input.putFloat((Color.green(px) - 127.5f) / 127.5f)
                    input.putFloat((Color.blue(px) - 127.5f) / 127.5f)
                }

            // 3. Kh·ªüi t·∫°o Output
            val output = ByteBuffer.allocateDirect(labels.size * 4).order(ByteOrder.nativeOrder())

            // 4. Ch·∫°y nh·∫≠n di·ªán (Inference)
            interpreter.run(input, output)

            val scores = FloatArray(labels.size)
            output.rewind()
            output.asFloatBuffer().get(scores)

            // 5. X·ª≠ l√Ω k·∫øt qu·∫£
            val idx = scores.indices.maxByOrNull { scores[it] } ?: 0
            val confidence = String.format("%.2f", scores[idx] * 100)
            return "${labels[idx]} (Confidence: $confidence%)"
        }
    }

    private fun updateStep(index: Int, completed: Boolean) {
        runOnUiThread {
            val textView = when (index) {
                0 -> tvAnalyzing
                1 -> tvDetecting
                2 -> tvIdentifying
                else -> return@runOnUiThread
            }

            val prefix = if (completed) "‚úÖ" else "‚ö™"
            val color = if (completed) Color.parseColor("#FFC107") else Color.WHITE

            textView.text = "$prefix ${loadingSteps[index]}"
            textView.setTextColor(color)
        }
    }

    // H√†m ƒëi·ªÅu h∆∞·ªõng th·ª±c t·∫ø
    private fun navigateToResultScreen(result: String, mode: String) {
        Log.i("LoadingActivity", "Recognition Complete! Result: $result")

        // ƒêi·ªÅu h∆∞·ªõng sang ResultActivity
        val intent = Intent(this@LoadingActivity, ResultActivity::class.java)
        intent.putExtra("RESULT", result)
        intent.putExtra("MODE", mode)
        startActivity(intent)
        finish()
    }
}